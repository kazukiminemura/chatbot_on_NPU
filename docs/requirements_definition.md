# DeepSeek-R1-Distill-Qwen-1.5B NPUチャットボット アプリケーション要件定義書

## 1. プロジェクト概要

### 1.1 目的
- DeepSeek-R1-Distill-Qwen-1.5Bモデル（INT4量子化版）をOpenVINOを使用してNPU上で実行
- ブラウザから利用可能な個人用チャットボットアプリケーションの構築
- 高速推論とリアルタイム対話の実現

### 1.2 対象ユーザー
- 個人ユーザー（1人での利用を想定）
- AI技術に興味があるエンドユーザー
- ローカル環境でのプライベートなAI対話を求めるユーザー

## 2. 機能要件

### 2.1 コア機能
1. **リアルタイムチャット機能**
   - ブラウザベースのチャットインターフェース
   - テキスト入力による質問・指示の送信
   - AIからのリアルタイム応答表示
   - ストリーミング応答対応（文字単位での逐次表示）

2. **モデル管理機能**
   - DeepSeek-R1-Distill-Qwen-1.5Bモデルの自動ダウンロード
   - OpenVINO形式への自動変換（必要に応じて）
   - NPUデバイスへの最適化配置

3. **会話履歴管理**
   - セッション内での会話履歴保持
   - 会話履歴のクリア機能
   - 過去の会話の参照機能

### 2.2 ユーザーインターフェース機能
1. **Webインターフェース**
   - レスポンシブデザイン（デスクトップ・モバイル対応）
   - 直感的なチャット画面
   - 入力エリア（テキストボックス）
   - 送信ボタン
   - 会話履歴表示エリア

2. **システム情報表示**
   - NPU使用状況の表示
   - モデル読み込み状態の表示
   - 応答時間の表示
   - システムリソース使用状況

### 2.3 設定・カスタマイズ機能
1. **応答パラメータ調整**
   - 最大トークン数設定
   - 温度パラメータ調整
   - Top-p/Top-k設定
   - 繰り返しペナルティ設定

2. **システム設定**
   - NPUデバイス選択
   - ログレベル設定
   - キャッシュ設定

## 3. 非機能要件

### 3.1 性能要件
- **応答時間**: 平均2秒以内での応答開始
- **スループット**: 秒間50トークン以上の生成速度
- **メモリ使用量**: 4GB以下でのモデル実行
- **NPU使用率**: 最適化されたNPUリソース活用

### 3.2 可用性要件
- **稼働時間**: ローカル環境での24時間稼働対応
- **エラー処理**: 適切なエラーメッセージ表示とリカバリ機能
- **自動復旧**: モデル読み込み失敗時の自動リトライ

### 3.3 セキュリティ要件
- **ローカル実行**: 全ての処理をローカル環境で完結
- **データプライバシー**: 会話データの外部送信なし
- **アクセス制御**: localhost限定のアクセス

### 3.4 互換性要件
- **OS**: Windows 10/11 (NPU対応)
- **ブラウザ**: Chrome, Firefox, Edge (最新版)
- **ハードウェア**: Intel NPU搭載デバイス

## 4. 技術要件

### 4.1 技術スタック
- **Backend**: Python 3.9+
- **Web Framework**: FastAPI
- **Frontend**: HTML5, CSS3, JavaScript (Vanilla)
- **AI Framework**: OpenVINO Runtime
- **Model Format**: GGUF → OpenVINO IR
- **WebSocket**: リアルタイム通信用

### 4.2 依存ライブラリ
- openvino[npu]
- transformers
- optimum-intel
- fastapi
- uvicorn
- websockets
- huggingface-hub

### 4.3 アーキテクチャ
```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Web Browser   │◄──►│   FastAPI       │◄──►│   OpenVINO      │
│   (Frontend)    │    │   (Backend)     │    │   (NPU Runtime) │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                              │
                              ▼
                       ┌─────────────────┐
                       │   Model Store   │
                       │   (Local Cache) │
                       └─────────────────┘
```

## 5. データ要件

### 5.1 モデルデータ
- **モデルサイズ**: 約1GB (DeepSeek-R1-Distill-Qwen-1.5B INT4)
- **フォーマット**: OpenVINO IR形式
- **保存場所**: ローカル`models/`ディレクトリ

### 5.2 設定データ
- **形式**: JSON形式の設定ファイル
- **内容**: モデルパラメータ、システム設定
- **保存場所**: `config.json`

### 5.3 ログデータ
- **形式**: 構造化ログ（JSON）
- **内容**: システムログ、エラーログ、パフォーマンスログ
- **保存場所**: `logs/`ディレクトリ

## 6. ユーザーシナリオ

### 6.1 基本利用フロー
1. アプリケーション起動
2. ブラウザでlocalhost:8000にアクセス
3. モデル読み込み完了を確認
4. チャット画面で質問を入力
5. 送信ボタンクリックまたはEnterキー
6. AIからの応答をリアルタイムで受信
7. 会話を継続

### 6.2 初回セットアップフロー
1. 依存関係のインストール
2. モデルの自動ダウンロード
3. OpenVINO形式への変換
4. NPUデバイスの検出・設定
5. サーバー起動

## 7. 制約事項

### 7.1 技術的制約
- NPU対応ハードウェアが必要
- OpenVINO NPUランタイムの要求仕様
- ローカル環境でのリソース制限

### 7.2 機能的制約
- 単一ユーザーでの利用に限定
- リアルタイム音声入出力は対象外
- ファイルアップロード機能は対象外

## 8. 今後の拡張予定

### 8.1 Phase 2 機能
- 複数モデルの切り替え機能
- 会話履歴の永続化
- プラグイン機能

### 8.2 Phase 3 機能
- 音声入出力対応
- 画像生成・解析機能
- カスタムファインチューニング対応

## 9. 成功指標

### 9.1 技術指標
- NPU使用率: 80%以上
- 平均応答時間: 2秒以内
- メモリ使用量: 4GB以下

### 9.2 ユーザビリティ指標
- セットアップ時間: 15分以内
- インターフェースの直感性
- エラー発生率: 1%以下

---

**文書作成日**: 2025年10月2日  
**バージョン**: 1.0  
**作成者**: AI Assistant